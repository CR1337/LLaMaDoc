{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70603b8-2604-461b-9851-1a81462ab786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e09534b1-f1a1-4e84-84dc-cf02c669561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "#with open('test_data.json', 'r') as file:\n",
    "#    data = json.load(file)\n",
    "\n",
    "#filtered_elements = [element for element in data if element.get('l') is False]\n",
    "#sampled_elements = random.sample(filtered_elements, min(100, len(filtered_elements)))\n",
    "\n",
    "#with open('100_last_test_data.json', 'w') as file:\n",
    "#    json.dump(sampled_elements, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28149c1-aaf2-4724-9658-d59af5aa9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pydantic_model import TestQuery\n",
    "from typing import Dict, Any\n",
    "\n",
    "def _do_request(\n",
    "        query: TestQuery,\n",
    "        endpoint: str\n",
    "    ) -> Dict[str, Any]:\n",
    "        response = requests.post(\n",
    "            url=f\"http://delos.eaalab.hpi.uni-potsdam.de:9002{endpoint}\",\n",
    "            json=query.model_dump()\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8050daf-cc35-4955-8fc2-a9ee75362c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('100_last_test_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "codes = [element.get('c') for element in data]\n",
    "docstrings = [element.get('d') for element in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9fe8c9c8-39fa-49df-afa6-c65ca6e491ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_generations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "baf2ed08-1fae-4619-a59d-bb645b03de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_codes = []\n",
    "split_codes.append(codes[:25])\n",
    "split_codes.append(codes[25:50])\n",
    "split_codes.append(codes[50:75])\n",
    "split_codes.append(codes[75:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b000212-8cbb-404e-ba95-c79c6a728e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docstrings = []\n",
    "split_docstrings.append(docstrings[:25])\n",
    "split_docstrings.append(docstrings[25:50])\n",
    "split_docstrings.append(docstrings[50:75])\n",
    "split_docstrings.append(docstrings[75:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "49945863-2481-4c30-bba2-29e7044a6889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(split_codes))\n",
    "print(len(split_codes[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dd49b80a-e924-44b6-99e4-8d3b6fe395aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_model import TestMethod, NoneTestParameters, GenerationParameters, SampleMethod\n",
    "\n",
    "gen_mid = \"google/codegemma-2b\"\n",
    "\n",
    "all_responses_old_model = {'results' : []}\n",
    "\n",
    "for i in range(4):\n",
    "    test_query = TestQuery(\n",
    "        mid=gen_mid,\n",
    "        codes=split_codes[i],\n",
    "        docstrings=split_docstrings[i],\n",
    "        test_method=TestMethod.UPDATE,\n",
    "        test_parameters=NoneTestParameters(\n",
    "            generation_parameters=GenerationParameters(\n",
    "                max_new_tokens=256,\n",
    "                sample_method=SampleMethod.TOP_P,\n",
    "                top_p=0.85,\n",
    "                temperature=0.5\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    response_old_model = _do_request(test_query, \"/test\")\n",
    "    all_responses_old_model['results'].extend(response_old_model['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f6e3345b-98b4-4f61-b612-fedb95441268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_model import TestMethod, NoneTestParameters, GenerationParameters, SampleMethod\n",
    "\n",
    "gen_mid = \"checkpoints/finetuned_0\"\n",
    "\n",
    "all_responses_finetuned_model = {'results' : []}\n",
    "\n",
    "for i in range(4):\n",
    "    test_query = TestQuery(\n",
    "        mid=gen_mid,\n",
    "        codes=split_codes[i],\n",
    "        docstrings=split_docstrings[i],\n",
    "        test_method=TestMethod.UPDATE,\n",
    "        test_parameters=NoneTestParameters(\n",
    "            generation_parameters=GenerationParameters(\n",
    "                max_new_tokens=256,\n",
    "                sample_method=SampleMethod.TOP_P,\n",
    "                top_p=0.85,\n",
    "                temperature=0.5\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    response_finetuned_model = _do_request(test_query, \"/test\")\n",
    "    all_responses_finetuned_model['results'].extend(response_finetuned_model['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "506ef996-aabf-4542-b776-267ec1cb6674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(codes))\n",
    "print(len(docstrings))\n",
    "print(len(all_responses_old_model['results']))\n",
    "print(len(all_responses_finetuned_model['results']))\n",
    "print(num_generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61230381-f5fe-4da0-a885-0c7484dc66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../open_ai_key_DO_NOT_PUSH.secret', 'r') as file:\n",
    "    api_key = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "21823a25-ed1a-4618-bf8e-05e2075ada5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "gpt3_completions = []\n",
    "\n",
    "for i in range(0):\n",
    "#for i in range(num_generations):\n",
    "    gpt3_completion = client.chat.completions.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages=[{\"role\": \"system\", \"content\": \"You are an experienced python software developer.\"},\n",
    "                    {\"role\": \"user\", \"content\": \"Rate how well the following three docstrings fit to the given python code. Rate each docstring seperately and don't compare them with each other.\"},\n",
    "                    {\"role\": \"user\", \"content\": \"Code example: \" + codes[i]},\n",
    "                    {\"role\": \"user\", \"content\": \"Docstring-0 example: \" + docstrings[i]},\n",
    "                    {\"role\": \"user\", \"content\": \"Docstring-1 example: \" + all_responses_old_model['results'][i]['updated_docstring']},\n",
    "                    {\"role\": \"user\", \"content\": \"Docstring-2 example: \" + all_responses_finetuned_model['results'][i]['updated_docstring']},\n",
    "                    {\"role\": \"user\", \"content\": \"Explain your reasoning for each docstring and then if Docstring-0 is the best, print 'docstring-0_better'. If Docstring-1 is the best, print 'docstring-1_better'. If Docstring-2 is the best, print 'docstring-2_better'. If none of the docstrings fit, print 'none_fit'.\"}\n",
    "          ]\n",
    "    )\n",
    "    gpt3_completions.append(gpt3_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "38234327-129b-4fbc-a35b-324156dbbb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51032\n"
     ]
    }
   ],
   "source": [
    "sums = 0\n",
    "for gpt3_completion in gpt3_completions:\n",
    "    try:\n",
    "        sums += gpt3_completion.usage.total_tokens\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f84051bc-2a42-425b-b0bc-f3528e53a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gpt_3_5_ratings.json\", \"w\") as f:\n",
    "    json.dump([gpt3_completion.choices[0].message.content for gpt3_completion in gpt3_completions], f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1f1823dd-7c10-4227-9d32-adc15f3b7ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gpt_3_5_ratings.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "gpt3_original_docstring = 0\n",
    "gpt3_old_model_updated_docstring = 0\n",
    "gpt3_finetuned_model_updated_docstring = 0\n",
    "gpt3_none_fit = 0\n",
    "\n",
    "for d in data:\n",
    "    if 'docstring-0_better' in d:\n",
    "        gpt3_original_docstring +=1\n",
    "    elif 'docstring-1_better' in d:\n",
    "        gpt3_old_model_updated_docstring +=1\n",
    "    elif 'docstring-2_better' in d:\n",
    "        gpt3_finetuned_model_updated_docstring +=1\n",
    "    elif 'none_fit' in d:\n",
    "        gpt3_none_fit +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2d2e29a0-489b-4ca8-9370-b7b2dc8155e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "42\n",
      "30\n",
      "25\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "print(gpt3_original_docstring)\n",
    "print(gpt3_old_model_updated_docstring)\n",
    "print(gpt3_finetuned_model_updated_docstring)\n",
    "print(gpt3_none_fit)\n",
    "print(gpt3_original_docstring + gpt3_old_model_updated_docstring + gpt3_finetuned_model_updated_docstring + gpt3_none_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "addecae2-5254-40e6-ae15-f558386bbc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "gpt4_completions = []\n",
    "\n",
    "for i in range(0):\n",
    "#for i in range(num_generations):\n",
    "    gpt4_completion = client.chat.completions.create(\n",
    "          model=\"gpt-4o\",\n",
    "          messages=[{\"role\": \"system\", \"content\": \"You are an experienced python software developer.\"},\n",
    "                    {\"role\": \"user\", \"content\": \"Rate how well the following three docstrings fit to the given python code. Rate each docstring seperately and don't compare them with each other.\"},\n",
    "                    {\"role\": \"user\", \"content\": \"Code example: \" + codes[i]},\n",
    "                    {\"role\": \"user\", \"content\": \"Docstring-0 example: \" + docstrings[i]},\n",
    "                    {\"role\": \"user\", \"content\": \"Docstring-1 example: \" + all_responses_old_model['results'][i]['updated_docstring']},\n",
    "                    {\"role\": \"user\", \"content\": \"Docstring-2 example: \" + all_responses_finetuned_model['results'][i]['updated_docstring']},\n",
    "                    {\"role\": \"user\", \"content\": \"Briefly explain your reasoning for each docstring and then if Docstring-0 is the best, print 'docstring-0_better'. If Docstring-1 is the best, print 'docstring-1_better'. If Docstring-2 is the best, print 'docstring-2_better'. If none of the docstrings fit, print 'none_fit'.\"}\n",
    "          ]\n",
    "    )\n",
    "    gpt4_completions.append(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dc9316ca-ba0e-40fa-b4f0-c7b5758740cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1677\n"
     ]
    }
   ],
   "source": [
    "sums = 0\n",
    "for gpt4_completion in gpt4_completions:\n",
    "    try:\n",
    "        sums += gpt4_completion.usage.total_tokens\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ccd495b4-10c4-4f90-92f9-1c75a695b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gpt_4_ratings.json\", \"w\") as f:\n",
    "    json.dump([gpt4_completion.choices[0].message.content for gpt4_completion in gpt4_completions], f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9a8b1180-647b-4f0d-aee4-fa6352ef150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Finetuning_Evaluation_Updated_Docstrings/gpt_4_ratings.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "gpt4_original_docstring = 0\n",
    "gpt4_old_model_updated_docstring = 0\n",
    "gpt4_finetuned_model_updated_docstring = 0\n",
    "gpt4_none_fit = 0\n",
    "\n",
    "for d in data:\n",
    "    if 'docstring-0_better' in d:\n",
    "        gpt4_original_docstring +=1\n",
    "    elif 'docstring-1_better' in d:\n",
    "        gpt4_old_model_updated_docstring +=1\n",
    "    elif 'docstring-2_better' in d:\n",
    "        gpt4_finetuned_model_updated_docstring +=1\n",
    "    elif 'none_fit' in d:\n",
    "        gpt4_none_fit +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8a239135-fb69-4da6-a9cd-d7a11309c2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(gpt4_original_docstring)\n",
    "print(gpt4_old_model_updated_docstring)\n",
    "print(gpt4_finetuned_model_updated_docstring)\n",
    "print(gpt4_none_fit)\n",
    "print(gpt4_original_docstring + gpt4_old_model_updated_docstring + gpt4_finetuned_model_updated_docstring + gpt4_none_fit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
