{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1b0e24-cbdf-4cde-ac99-c1bb51c6f206",
   "metadata": {},
   "source": [
    "Python Notebook for finetuning our model. Heavily inspired by the finetuning example presented in class (HPI, AI for Software Engineering, 14.05.2024). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d5d597-3d86-4baa-865c-d3bd24a31e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a2ea83-1adc-43fa-ab6b-aa7c9c3fda19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import huggingface_hub\n",
    "import datasets\n",
    "from transformers import GemmaTokenizer, AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "from accelerate import Accelerator, DataLoaderConfiguration\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b65e4-443e-45ea-b3f2-691d95307087",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda:0')\n",
    "model_id = \"google/codegemma-1.1-2b\"\n",
    "tokenizer = GemmaTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=gpu, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5202b3ae-06f7-4f91-852a-5532222e1ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, max_new_tokens=200):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt').to(gpu)\n",
    "    outputs = model.generate(inputs, max_new_tokens=max_new_tokens)\n",
    "    return tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa9bf567-7266-470d-ab29-121a9b572b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><|fim_prefix|>def add(x, y) -> int:\n",
      "\n",
      "    \"\"\"<|fim_suffix|>\"\"\"\n",
      "        return x + y<|fim_middle|>\n",
      "    This function adds two numbers and returns the result.\n",
      "\n",
      "    Args:\n",
      "        x (int): The first number to be added.\n",
      "        y (int): The second number to be added.\n",
      "\n",
      "    Returns:\n",
      "        int: The sum of the two input numbers.\n",
      "    <|file_separator|><eos>\n"
     ]
    }
   ],
   "source": [
    "print(generate(\"<|fim_prefix|>def add(x, y) -> int:\\n\\n    \\\"\\\"\\\"<|fim_suffix|>\\\"\\\"\\\"\\n        return x + y<|fim_middle|>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac5a57a-d08d-4631-ae2c-560449bb3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_dataset('json', split='train', data_files='train_data.json')\n",
    "#print(ds[0]['e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1dff58c-3b78-46f0-8a8d-470592fce246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(dataset_row):\n",
    "    source = dataset_row['e']\n",
    "    input_ids = tokenizer.encode(source) + [tokenizer.eos_token_id]\n",
    "    labels = input_ids.copy()\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84f5de18-373d-4366-9d2d-9fb11d174916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951048f18ad3400b853d8fcfcb41da63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = ds.map(tokenize, remove_columns=['l', 'd', 'c', 'e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60f5db7b-90b8-4a2e-9ac7-cad9fc532f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 40000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e179f7-ac79-474d-a758-212413003143",
   "metadata": {},
   "source": [
    "Adjusted blocking in order to avoid splitting code examples in the middle. If an example does not fit into the current block, pad it with EOS-tokens and put the example into the next block. The block size 512 is larger than our longest example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90b4174a-7105-4d6d-aeb7-0e902a8406bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(data, block_size=512):\n",
    "\n",
    "    blocked_ids = [[]]\n",
    "    current_block = 0\n",
    "    current_block_capacity = block_size\n",
    "    \n",
    "    for i in range(len(data['input_ids'])):\n",
    "        example = data['input_ids'][i]\n",
    "        if(len(example) > block_size):\n",
    "            continue\n",
    "        if(current_block_capacity - len(example) >= 0):\n",
    "            blocked_ids[current_block] = blocked_ids[current_block] + example\n",
    "            current_block_capacity -= len(example)\n",
    "        else:\n",
    "            while(len(blocked_ids[current_block]) < block_size):\n",
    "                blocked_ids[current_block].append(tokenizer.eos_token_id)\n",
    "            \n",
    "            blocked_ids.append([])\n",
    "            current_block += 1\n",
    "            current_block_capacity = block_size\n",
    "    while(len(blocked_ids[current_block]) < block_size):\n",
    "            blocked_ids[current_block].append(tokenizer.eos_token_id)\n",
    "        \n",
    "    assert len(blocked_ids) > 0\n",
    "    return {\n",
    "        'input_ids': blocked_ids,\n",
    "        'labels': blocked_ids.copy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "695c4205-b8aa-4b21-9f26-b7dbd6420e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = tokenized_data.train_test_split(\n",
    "    test_size = 0.1,\n",
    "    shuffle = True,\n",
    "    seed = 421337)\n",
    "test_data = split_dataset['test']\n",
    "train_data = split_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90bd69c2-65cc-4f0e-8356-edfcad36785f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa419072787249df97368c20fc027a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e57bda0f604e06a7fd3ceaff7dffca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_blocks = test_data.map(block, batched=True)\n",
    "train_data_blocks = train_data.map(block, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c0bec15-6fb1-4ec2-a4a4-5fb28d5e4030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 67, 141, 1293, 4830, 235278, 1053, 235269, 24826, 1245, 109, 141, 1676, 69, 1676, 108, 149, 16045, 589, 2011, 235265, 1353, 235298, 21837, 235298, 4705, 649, 2011, 235265, 21837, 235298, 16045, 235278, 15399, 199872, 235248, 235276, 3013, 108, 145, 15399, 589, 24826, 963, 12568, 108, 145, 15399, 589, 24826, 235265, 67479, 235278, 235274, 235269, 728, 235274, 235275, 108, 145, 746, 517, 575, 2011, 235265, 16116, 235292, 108, 149, 15399, 589, 517, 235278, 15399, 235275, 109, 145, 15399, 589, 2011, 235265, 15842, 235278, 15399, 235265, 67479, 235278, 235274, 235269, 728, 235274, 1269, 108, 145, 773, 24826, 68, 235292, 1728, 24826, 235292, 892, 235305, 235269, 584, 235269, 640, 235307, 108, 235292, 773, 235292, 892, 235305, 235269, 584, 235269, 640, 235307, 70, 1, 2, 67, 1293, 5985, 235298, 1149, 235278, 235272, 1245, 109, 141, 1676, 69, 1676, 108, 145, 773, 1295, 235278, 235272, 235275, 68, 9954, 593, 685, 2067, 70, 1, 2, 67, 141, 1293, 9616, 235278, 1053, 235269, 89167, 235298, 2222, 235293, 5440, 235269, 5231, 19649, 1245, 109, 141, 1676, 69, 1676, 108, 149, 9054, 235298, 2222, 589, 89167, 235298, 2222, 689, 2011, 3163, 3622, 235265, 20197, 235298, 103457, 235298, 16269, 108, 145, 648, 9616, 235298, 2222, 603, 4090, 235292, 108, 149, 13535, 42343, 235278, 108, 153, 235281, 24758, 89167, 235298, 2222, 40481, 16395, 235365, 236343, 16395, 75418, 97242, 89167, 203585, 235269, 72009, 585, 33836, 75418, 28742, 46685, 1457, 6375, 55653, 235265, 23688, 235281, 108, 149, 235275, 109, 145, 1053, 3163, 1217, 589, 6599, 4834, 4537, 235265, 7329, 2320, 9054, 235278, 108, 149, 2222, 235293, 9054, 235298, 2222, 235269, 30102, 235293, 235274, 235276, 108, 145, 235275, 108, 145, 1053, 3163, 3446, 235298, 39038, 235298, 29409, 645, 108, 145, 1053, 3163, 2000, 589, 2011, 3163, 1217, 235265, 2234, 235298, 7499, 645, 68, 15965, 32487, 110209, 42217, 75418, 108, 235292, 1728, 89167, 235298, 2222, 235292, 235248, 75418, 50288, 72009, 548, 235303, 235288, 12535, 650, 174033, 113497, 235284, 235286, 6375, 55653, 235265, 23688, 920, 137910, 548, 235303, 235288, 12535, 650, 174033, 113497, 235284, 235286, 6375, 55653, 235265, 23688, 235303, 108, 235292, 773, 235292, 70, 1, 2, 67, 1293, 157198, 235298, 7310, 235278, 1053, 235269, 1141, 1245, 109, 141, 1676, 69, 1676, 108, 145, 773, 1141, 68, 13740, 235292, 108, 235278, 1149, 1245, 4820, 19017, 1411, 3772, 70, 1, 2, 67, 1293, 2121, 235298, 818, 235298, 3622, 235298, 24636, 235298, 1665, 235298, 14259, 4409, 109, 141, 1676, 69, 1676, 108, 145, 3041, 53659, 235265, 84496, 235278, 3744, 140539, 2180, 1245, 108, 145, 3622, 235265, 818, 235298, 3622, 885, 16833, 235283, 2195, 235290, 3622, 235283, 883, 235290, 24636, 235290, 1665, 235290, 14259, 235265, 37200, 1388, 68, 4417, 674, 4103, 51372, 235265, 3744, 140539, 2180, 235376, 603, 9244, 1185, 142, 82318, 574, 577, 947, 476, 2173, 235290, 64896, 4546, 2482, 235265, 70, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [2, 67, 141, 1293, 4830, 235278, 1053, 235269, 24826, 1245, 109, 141, 1676, 69, 1676, 108, 149, 16045, 589, 2011, 235265, 1353, 235298, 21837, 235298, 4705, 649, 2011, 235265, 21837, 235298, 16045, 235278, 15399, 199872, 235248, 235276, 3013, 108, 145, 15399, 589, 24826, 963, 12568, 108, 145, 15399, 589, 24826, 235265, 67479, 235278, 235274, 235269, 728, 235274, 235275, 108, 145, 746, 517, 575, 2011, 235265, 16116, 235292, 108, 149, 15399, 589, 517, 235278, 15399, 235275, 109, 145, 15399, 589, 2011, 235265, 15842, 235278, 15399, 235265, 67479, 235278, 235274, 235269, 728, 235274, 1269, 108, 145, 773, 24826, 68, 235292, 1728, 24826, 235292, 892, 235305, 235269, 584, 235269, 640, 235307, 108, 235292, 773, 235292, 892, 235305, 235269, 584, 235269, 640, 235307, 70, 1, 2, 67, 1293, 5985, 235298, 1149, 235278, 235272, 1245, 109, 141, 1676, 69, 1676, 108, 145, 773, 1295, 235278, 235272, 235275, 68, 9954, 593, 685, 2067, 70, 1, 2, 67, 141, 1293, 9616, 235278, 1053, 235269, 89167, 235298, 2222, 235293, 5440, 235269, 5231, 19649, 1245, 109, 141, 1676, 69, 1676, 108, 149, 9054, 235298, 2222, 589, 89167, 235298, 2222, 689, 2011, 3163, 3622, 235265, 20197, 235298, 103457, 235298, 16269, 108, 145, 648, 9616, 235298, 2222, 603, 4090, 235292, 108, 149, 13535, 42343, 235278, 108, 153, 235281, 24758, 89167, 235298, 2222, 40481, 16395, 235365, 236343, 16395, 75418, 97242, 89167, 203585, 235269, 72009, 585, 33836, 75418, 28742, 46685, 1457, 6375, 55653, 235265, 23688, 235281, 108, 149, 235275, 109, 145, 1053, 3163, 1217, 589, 6599, 4834, 4537, 235265, 7329, 2320, 9054, 235278, 108, 149, 2222, 235293, 9054, 235298, 2222, 235269, 30102, 235293, 235274, 235276, 108, 145, 235275, 108, 145, 1053, 3163, 3446, 235298, 39038, 235298, 29409, 645, 108, 145, 1053, 3163, 2000, 589, 2011, 3163, 1217, 235265, 2234, 235298, 7499, 645, 68, 15965, 32487, 110209, 42217, 75418, 108, 235292, 1728, 89167, 235298, 2222, 235292, 235248, 75418, 50288, 72009, 548, 235303, 235288, 12535, 650, 174033, 113497, 235284, 235286, 6375, 55653, 235265, 23688, 920, 137910, 548, 235303, 235288, 12535, 650, 174033, 113497, 235284, 235286, 6375, 55653, 235265, 23688, 235303, 108, 235292, 773, 235292, 70, 1, 2, 67, 1293, 157198, 235298, 7310, 235278, 1053, 235269, 1141, 1245, 109, 141, 1676, 69, 1676, 108, 145, 773, 1141, 68, 13740, 235292, 108, 235278, 1149, 1245, 4820, 19017, 1411, 3772, 70, 1, 2, 67, 1293, 2121, 235298, 818, 235298, 3622, 235298, 24636, 235298, 1665, 235298, 14259, 4409, 109, 141, 1676, 69, 1676, 108, 145, 3041, 53659, 235265, 84496, 235278, 3744, 140539, 2180, 1245, 108, 145, 3622, 235265, 818, 235298, 3622, 885, 16833, 235283, 2195, 235290, 3622, 235283, 883, 235290, 24636, 235290, 1665, 235290, 14259, 235265, 37200, 1388, 68, 4417, 674, 4103, 51372, 235265, 3744, 140539, 2180, 235376, 603, 9244, 1185, 142, 82318, 574, 577, 947, 476, 2173, 235290, 64896, 4546, 2482, 235265, 70, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(test_data_blocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce94f6e0-1bb1-4741-a9fd-511ab4921629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "from transformers import get_linear_schedule_with_warmup, DataCollatorForLanguageModeling\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dbd144f-dff6-4dde-a6d9-a2f6364bd94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    target_modules=['q_proj', 'v_proj'],\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "835cf93c-01e4-47f5-8881-f3b3bdaa17f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f3000e3-508f-4da2-90c0-9d47345dcc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 921,600 || all params: 2,507,094,016 || trainable%: 0.036759690467068624\n"
     ]
    }
   ],
   "source": [
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4293d831-684d-4e84-9294-9490fbe4de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fe6b7b8-39ca-4bf6-8171-82cd934da86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "collator = DataCollatorForLanguageModeling(\n",
    "            tokenizer,\n",
    "            mlm=False,\n",
    "            pad_to_multiple_of=8,\n",
    "            return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbacfb9a-3f92-47c2-9a1b-2a28e08d5a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data_blocks, shuffle=True, collate_fn=collator, batch_size=batch_size)\n",
    "eval_dataloader = DataLoader(test_data_blocks, shuffle=True, collate_fn=collator, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ba4d3a6-30b0-4953-8430-99af7fd31168",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be54d7-11b8-4816-b132-9afee7efa12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        outputs = model(**batch.to(gpu))\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.detach().cpu().float()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch.to(gpu))\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.detach().cpu().float()\n",
    "\n",
    "    eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "    train_epoch_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"{epoch=}: {train_epoch_loss=} {eval_epoch_loss=}\")\n",
    "\n",
    "\n",
    "    peft_model.save_pretrained(f'./finetuning_checkpoints/checkpoint-ep{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa6e8c9-be11-4d52-8c69-08ee6c0c982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generate(\"<|fim_prefix|>def add(x, y) -> int:\\n\\n    \\\"\\\"\\\"<|fim_suffix|>\\\"\\\"\\\"\\n        return x + y<|fim_middle|>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89ba04c6-e60e-49cc-963c-a9d2c5a1bf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eff1e08da1c4cd192c6300b81118117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><|fim_prefix|>def add(x, y) -> int:\n",
      "\n",
      "    \"\"\"<|fim_suffix|>\"\"\"\n",
      "        return x + y<|fim_middle|>Add two numbers.<|file_separator|><eos>\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"finetuning_checkpoints/checkpoint-ep9\"\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(checkpoint).to(gpu)\n",
    "\n",
    "def finetuned_generate(prompt, max_new_tokens=200):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt').to(gpu)\n",
    "    outputs = finetuned_model.generate(inputs, max_new_tokens=max_new_tokens)\n",
    "    return tokenizer.decode(outputs[0])\n",
    "\n",
    "print(finetuned_generate(\"<|fim_prefix|>def add(x, y) -> int:\\n\\n    \\\"\\\"\\\"<|fim_suffix|>\\\"\\\"\\\"\\n        return x + y<|fim_middle|>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
